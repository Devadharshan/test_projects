import os
import time

# Directories to scan
directories = ["C:\\", "D:\\"]

# Output prom file
out_file = r"C:\node_exporter\textfile_inputs\large_files.prom"

def scan_large_files(dirs, size_limit_gb=1):
    metrics = []
    size_limit = size_limit_gb * (1024 ** 3)

    for d in dirs:
        file_count = 0
        total_size = 0

        for root, _, files in os.walk(d):
            for f in files:
                try:
                    path = os.path.join(root, f)
                    size = os.path.getsize(path)
                    if size > size_limit:
                        file_count += 1
                        total_size += size
                except Exception as e:
                    # skip inaccessible files
                    continue  

        # Export metrics
        metrics.append('large_files_count{{directory="{0}"}} {1}'.format(d, file_count))
        metrics.append('large_files_total_size_bytes{{directory="{0}"}} {1}'.format(d, total_size))

    return metrics

if __name__ == "__main__":
    start = time.time()
    metrics = scan_large_files(directories)

    runtime = time.time() - start
    metrics.append('scan_runtime_seconds {0}'.format(runtime))

    with open(out_file, "w") as f:
        f.write("\n".join(metrics) + "\n")
