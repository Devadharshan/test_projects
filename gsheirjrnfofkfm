import os
import pandas as pd
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
from datetime import datetime, timedelta, timezone

# ---------------- CONFIG ----------------
CSV_DIR = r"C:\path\to\csvs"
PUSHGATEWAY_URL = "http://localhost:9091"
JOB_NAME = "bp_aggregated_summary"

IST = timezone(timedelta(hours=5, minutes=30))

WINDOWS = {
    "today": 0,
    "yesterday": 1,
    "last7days": 7,
    "last30days": 30
}

# ---------------- HELPERS ----------------
def parse_date_from_filename(filename):
    try:
        return datetime.strptime(filename.split("__")[-1].split(".csv")[0], "%Y-%m-%d").date()
    except:
        return None

def get_csv_files(base_dir):
    files = []
    for f in os.listdir(base_dir):
        if f.endswith(".csv") and "_summary" not in f.lower():
            file_date = parse_date_from_filename(f)
            if file_date:
                files.append((os.path.join(base_dir, f), file_date))
    return files

def windows_for_file(file_date, today):
    windows = []
    if file_date == today:
        windows.append("today")
    if file_date == today - timedelta(days=1):
        windows.append("yesterday")
    if today - timedelta(days=6) <= file_date <= today:
        windows.append("last7days")
    if today - timedelta(days=29) <= file_date <= today:
        windows.append("last30days")
    return windows

# ---------------- MAIN ----------------
def push_metrics():
    today = datetime.now(IST).date()
    files = get_csv_files(CSV_DIR)
    if not files:
        print("No CSV files found")
        return

    registry = CollectorRegistry()

    # Gauges
    g_total_trades = Gauge("bp_total_trades", "Total trades per BP", ["bp_name", "job_details", "window", "file_date"], registry=registry)
    g_total_duration = Gauge("bp_total_duration", "Total duration per BP", ["bp_name", "job_details", "window", "file_date"], registry=registry)
    g_avg_duration_per_trade = Gauge("bp_avg_duration_per_trade", "Average duration per trade per BP", ["bp_name", "job_details", "window", "file_date"], registry=registry)
    g_job_count = Gauge("bp_job_count", "Number of jobs per BP", ["bp_name", "job_details", "window", "file_date"], registry=registry)
    g_avg_duration_per_trade_job = Gauge("bp_avg_duration_per_trade_job", "Average duration per trade per BP + JobDetails", ["bp_name", "job_details", "window", "file_date"], registry=registry)
    g_avg_duration_per_bp = Gauge("bp_avg_duration_per_bp", "Average duration per trade per BP", ["bp_name", "window", "file_date"], registry=registry)

    for file_path, file_date in files:
        try:
            df = pd.read_csv(file_path)
            # Normalize column names
            df.columns = [c.strip().upper().replace(" ", "_") for c in df.columns]

            required = ["BP_NAME", "JOBDETAILS", "DURATION", "NO_OF_TRADES", "DURATIONPERTRADE"]
            if not all(col in df.columns for col in required):
                print(f"Missing required columns in {file_path}, skipping")
                continue

            # Convert numeric
            df["DURATION"] = pd.to_numeric(df["DURATION"], errors="coerce").fillna(0)
            df["NO_OF_TRADES"] = pd.to_numeric(df["NO_OF_TRADES"], errors="coerce").fillna(0)
            df["DURATIONPERTRADE"] = pd.to_numeric(df["DURATIONPERTRADE"], errors="coerce").fillna(0)

            # BP + JobDetails aggregation
            group_job = df.groupby(["BP_NAME", "JOBDETAILS"]).agg(
                total_trades=("NO_OF_TRADES", "sum"),
                total_duration=("DURATION", "sum"),
                avg_duration_per_trade=("DURATIONPERTRADE", "mean"),
                job_count=("JOBDETAILS", "count"),
                avg_duration_per_trade_job=("DURATIONPERTRADE", "mean")
            ).reset_index()

            # BP-level average duration per BP
            group_bp = df.groupby("BP_NAME").agg(
                avg_duration_per_bp=("DURATIONPERTRADE", "mean")
            ).reset_index()

            # Windows calculation
            windows = windows_for_file(file_date, today)
            if not windows:
                continue

            # Push BP + JobDetails
            for _, row in group_job.iterrows():
                for w in windows:
                    labels = {
                        "bp_name": row["BP_NAME"],
                        "job_details": row["JOBDETAILS"],
                        "window": w,
                        "file_date": str(file_date)
                    }
                    g_total_trades.labels(**labels).set(row["total_trades"])
                    g_total_duration.labels(**labels).set(row["total_duration"])
                    g_avg_duration_per_trade.labels(**labels).set(row["avg_duration_per_trade"])
                    g_job_count.labels(**labels).set(row["job_count"])
                    g_avg_duration_per_trade_job.labels(**labels).set(row["avg_duration_per_trade_job"])

            # Push BP-level average duration
            for _, row in group_bp.iterrows():
                for w in windows:
                    labels = {
                        "bp_name": row["BP_NAME"],
                        "window": w,
                        "file_date": str(file_date)
                    }
                    g_avg_duration_per_bp.labels(**labels).set(row["avg_duration_per_bp"])

        except Exception as e:
            print(f"Error processing file {file_path}: {e}")

    # Push to gateway
    push_to_gateway(PUSHGATEWAY_URL, job=JOB_NAME, registry=registry)
    print("âœ… Metrics pushed successfully!")

if __name__ == "__main__":
    push_metrics()