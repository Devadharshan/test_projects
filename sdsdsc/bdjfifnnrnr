#!/usr/bin/env python3
"""
push_bp_trend_raw.py - Full version with all changes

- Trend-only (no aggregations) raw row exporter.
- Computes time_taken from Start/End columns (dayfirst parsing).
- Sends metrics to Pushgateway at http://localhost:9091
- Numeric gauges for each numeric column.
- Raw table gauge includes all CSV columns including Start/End times.
- Windows: today, yesterday, last_7_days, last_30_days (only if CSV exists)
"""
import os
import re
import pandas as pd
from datetime import datetime, timedelta, timezone
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

# Python 3.9+: zoneinfo
try:
    from zoneinfo import ZoneInfo
    IST = ZoneInfo("Asia/Kolkata")
except Exception:
    IST = timezone(timedelta(hours=5, minutes=30))

# ---------------- CONFIG ----------------
DATA_FOLDER = r"C:\bpmetrics\data"  # <-- change to your folder
PUSHGATEWAY = "http://localhost:9091"

JOB_SUMMARY_RAW = "bp_summary_raw"
JOB_NON_SUMMARY_RAW = "bp_non_summary_raw"
JOB_NON_SUMMARY_TABLE = "bp_non_summary_raw_table"

# Exact column names in CSV
START_COL = "Start Time"
END_COL = "End Time"
TRADES_COL = "No of Trades"

# ---------------- HELPERS ----------------
def read_csv_safely(path):
    try:
        return pd.read_csv(path, dtype=str)
    except UnicodeDecodeError:
        return pd.read_csv(path, encoding="latin-1", dtype=str)
    except Exception as e:
        print(f"[read_csv_safely] Error reading {path}: {e}")
        return pd.DataFrame()

def extract_date_from_filename(fname):
    m = re.findall(r"(\d{4}-\d{2}-\d{2})", fname)
    if not m:
        return None
    try:
        return datetime.strptime(m[-1], "%Y-%m-%d").date()
    except Exception:
        return None

def clean_label_key(k: str) -> str:
    if k is None:
        return "unknown"
    s = str(k).strip().lower()
    s = re.sub(r'[^a-z0-9_]', '_', s)
    if not re.match(r'^[a-z]', s):
        s = 'k_' + s
    return s

def clean_label_value(v: str) -> str:
    if v is None:
        return "unknown"
    s = str(v).strip()
    if s == "":
        return "unknown"
    return re.sub(r'[^A-Za-z0-9_:./@-]', '_', s)

def is_number_like(s):
    if s is None:
        return False
    s = str(s).strip()
    if s == "":
        return False
    try:
        float(s.replace(",", ""))
        return True
    except:
        return False

def to_float(s):
    if s is None:
        return None
    s = str(s).strip()
    if s == "" or s.lower() == "nan":
        return None
    try:
        return float(s.replace(",", ""))
    except:
        return None

def windows_for_date(d, today_date, available_dates):
    windows = []
    if d is None:
        return windows
    yesterday = today_date - timedelta(days=1)
    if d == today_date:
        windows.append("today")
    if d == yesterday:
        windows.append("yesterday")
    if any((today_date - timedelta(days=i)) in available_dates for i in range(7)):
        if (today_date - timedelta(days=6)) <= d <= today_date:
            windows.append("last_7_days")
    if any((today_date - timedelta(days=i)) in available_dates for i in range(30)):
        if (today_date - timedelta(days=29)) <= d <= today_date:
            windows.append("last_30_days")
    return windows

# ---------------- MAIN ----------------
def main():
    now_ist = datetime.now(IST)
    today_date = now_ist.date()

    files = sorted([f for f in os.listdir(DATA_FOLDER) if f.lower().endswith(".csv")])
    if not files:
        print(f"[main] No CSV files found in {DATA_FOLDER}")
        return

    summary_rows = []
    non_summary_rows = []

    for fname in files:
        full = os.path.join(DATA_FOLDER, fname)
        df = read_csv_safely(full)
        if df.empty:
            continue
        file_date = extract_date_from_filename(fname)
        df["file_name"] = fname
        df["file_date"] = file_date
        if "_summary" in fname.lower():
            summary_rows.append(df)
        else:
            non_summary_rows.append(df)

    # Combine all rows
    summary_df = pd.concat(summary_rows, ignore_index=True) if summary_rows else pd.DataFrame()
    non_summary_df = pd.concat(non_summary_rows, ignore_index=True) if non_summary_rows else pd.DataFrame()

    # Track available CSV dates
    available_dates = set()
    for df in summary_rows + non_summary_rows:
        available_dates.update(df['file_date'].dropna().unique())

    # ---------------- Non-summary: compute time_taken and durationpertrade ----------------
    if not non_summary_df.empty:
        try:
            s = pd.to_datetime(non_summary_df[START_COL], dayfirst=True, errors="coerce")
            e = pd.to_datetime(non_summary_df[END_COL], dayfirst=True, errors="coerce")
            non_summary_df["time_taken"] = (e - s).dt.total_seconds()
            non_summary_df["time_taken"] = non_summary_df["time_taken"].where(non_summary_df["time_taken"].notna(), None)
        except Exception:
            non_summary_df["time_taken"] = None

        # duration column
        non_summary_df["duration"] = non_summary_df["time_taken"]

        # duration per trade
        non_summary_df["_trades_num"] = non_summary_df[TRADES_COL].apply(to_float) if TRADES_COL in non_summary_df.columns else None
        def compute_dpt(row):
            dur = to_float(row.get("duration"))
            tr = row.get("_trades_num")
            if dur is None or tr is None or tr == 0:
                return None
            return dur / tr
        non_summary_df["durationpertrade"] = non_summary_df.apply(compute_dpt, axis=1)
        if "_trades_num" in non_summary_df.columns:
            non_summary_df.drop(columns=["_trades_num"], inplace=True)

    # ---------------- Prepare registries ----------------
    summary_registry = CollectorRegistry()
    non_summary_registry = CollectorRegistry()
    raw_table_registry = CollectorRegistry()

    # ---------------- Prepare gauges ----------------
    def prepare_gauges(df, prefix, registry):
        gauges = {}
        if df.empty:
            return gauges
        numeric_cols = [c for c in df.columns if is_number_like(df[c].dropna().iloc[0])]
        label_cols = [c for c in df.columns if c not in numeric_cols + ["file_name","file_date"]]
        label_keys = [clean_label_key(c) for c in label_cols] + ["file_name","file_date","window"]
        for col in numeric_cols:
            metric_name = prefix + "_" + clean_label_key(col)
            if "duration" in col.lower() and not metric_name.endswith("_seconds"):
                metric_name += "_seconds"
            gauges[col] = (Gauge(metric_name, f"{metric_name} (from csv {col})", labelnames=label_keys, registry=registry), metric_name, label_keys)
        return gauges

    summary_gauges = prepare_gauges(summary_df, "new_data_summary_row", summary_registry)
    non_summary_gauges = prepare_gauges(non_summary_df, "new_data_non_summary_row", non_summary_registry)

    # Raw table gauge: all columns numeric or string
    if not non_summary_df.empty:
        raw_cols = list(non_summary_df.columns)
        raw_label_keys = [clean_label_key(c) for c in raw_cols if c not in ["duration","durationpertrade"]] + ["file_name","file_date","window"]
        raw_gauges = {}
        for col in ["duration","durationpertrade"]:
            if col in non_summary_df.columns:
                metric_name = "bp_non_summary_raw_" + clean_label_key(col)
                raw_gauges[col] = (Gauge(metric_name, f"{metric_name} from csv", labelnames=raw_label_keys, registry=raw_table_registry), metric_name, raw_label_keys)
    
    # ---------------- Push rows ----------------
    def push_rows(df, gauges_map, registry):
        if df.empty or not gauges_map:
            return
        numeric_cols = set(gauges_map.keys())
        for idx, row in df.iterrows():
            file_date_obj = row.get("file_date")
            windows = windows_for_date(file_date_obj, today_date, available_dates)
            if not windows:
                continue
            # labels base
            label_items = {}
            for col in df.columns:
                if col in numeric_cols + ["file_name","file_date"]:
                    continue
                label_items[clean_label_key(col)] = clean_label_value(row.get(col))
            for w in windows:
                label_items_with_window = dict(label_items)
                label_items_with_window["file_name"] = clean_label_value(row.get("file_name"))
                label_items_with_window["file_date"] = str(row.get("file_date"))
                label_items_with_window["window"] = w
                for col, (gauge_obj, metric_name, label_keys) in gauges_map.items():
                    val = to_float(row.get(col)) if col in row else 0.0
                    label_values = [label_items_with_window.get(lk,"unknown") for lk in label_keys]
                    gauge_obj.labels(*label_values).set(val if val is not None else 0.0)

    # ---------------- Push to Pushgateway ----------------
    if summary_gauges:
        push_rows(summary_df, summary_gauges, summary_registry)
        push_to_gateway(PUSHGATEWAY, job=JOB_SUMMARY_RAW, registry=summary_registry)
        print(f"Pushed summary raw -> {JOB_SUMMARY_RAW}")

    if non_summary_gauges:
        push_rows(non_summary_df, non_summary_gauges, non_summary_registry)
        push_to_gateway(PUSHGATEWAY, job=JOB_NON_SUMMARY_RAW, registry=non_summary_registry)
        print(f"Pushed non-summary raw -> {JOB_NON_SUMMARY_RAW}")

    if not non_summary_df.empty and raw_gauges:
        push_rows(non_summary_df, raw_gauges, raw_table_registry)
        push_to_gateway(PUSHGATEWAY, job=JOB_NON_SUMMARY_TABLE, registry=raw_table_registry)
        print(f"Pushed raw table -> {JOB_NON_SUMMARY_TABLE}")

    print("Done. Check Pushgateway:", PUSHGATEWAY)

if __name__ == "__main__":
    main()