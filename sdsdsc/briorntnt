#!/usr/bin/env python3
"""
push_bp_trend_raw.py

- Trend-only (no aggregations) raw row exporter.
- Forces IST timezone for 'today', 'yesterday', 'last_7_days', 'last_30_days'.
- Computes time_taken from Start/End columns (dayfirst parsing).
- Sends metrics to Pushgateway at http://localhost:9091
- Jobs:
    - bp_summary_raw
    - bp_non_summary_raw
    - bp_raw_table

Edit DATA_FOLDER to your CSV directory before running.
Requires: pip install pandas prometheus_client
"""
import os
import re
import pandas as pd
from datetime import datetime, timedelta, timezone
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

# ---------------- CONFIG ----------------
DATA_FOLDER = r"C:\bpmetrics\data"   # <-- change to your folder
PUSHGATEWAY = "http://localhost:9091"

JOB_SUMMARY_RAW = "bp_summary_raw"
JOB_NON_SUMMARY_RAW = "bp_non_summary_raw"
JOB_RAW_TABLE = "bp_raw_table"

# ---------------- TIMEZONE ----------------
IST = timezone(timedelta(hours=5, minutes=30))

# ---------------- HELPERS ----------------
def read_csv_safely(path):
    try:
        return pd.read_csv(path, dtype=str)  # read as strings first
    except UnicodeDecodeError:
        return pd.read_csv(path, encoding="latin-1", dtype=str)
    except Exception as e:
        print(f"[read_csv_safely] Error reading {path}: {e}")
        return pd.DataFrame()

def extract_date_from_filename(fname):
    m = re.findall(r"(\d{4}-\d{2}-\d{2})", fname)
    if not m:
        return None
    try:
        return datetime.strptime(m[-1], "%Y-%m-%d").date()
    except Exception:
        return None

def clean_label_key(k: str) -> str:
    if k is None:
        return "unknown"
    s = str(k).strip().lower()
    s = re.sub(r'[^a-z0-9_]', '_', s)
    if not re.match(r'^[a-z]', s):
        s = 'k_' + s
    return s

def clean_label_value(v: str) -> str:
    if v is None:
        return "unknown"
    s = str(v).strip()
    if s == "":
        return "unknown"
    return re.sub(r'[^A-Za-z0-9_:./@-]', '_', s)

def is_number_like(s):
    if s is None:
        return False
    s = str(s).strip()
    if s == "":
        return False
    s2 = s.replace(",", "")
    try:
        float(s2)
        return True
    except:
        return False

def to_float(s):
    if s is None:
        return None
    s = str(s).strip()
    if s == "" or s.lower() == "nan":
        return None
    try:
        return float(s.replace(",", ""))
    except:
        return None

def windows_for_date(d, today_date):
    windows = []
    if d is None:
        return windows
    yesterday = today_date - timedelta(days=1)
    if d == today_date:
        windows.append("today")
    if d == yesterday:
        windows.append("yesterday")
    if (today_date - timedelta(days=6)) <= d <= today_date:
        windows.append("last_7_days")
    if (today_date - timedelta(days=29)) <= d <= today_date:
        windows.append("last_30_days")
    return windows

# ---------------- MAIN ----------------
def main():
    now_ist = datetime.now(IST)
    today_date = now_ist.date()

    files = sorted([f for f in os.listdir(DATA_FOLDER) if f.lower().endswith(".csv")])
    if not files:
        print(f"[main] No CSV files found in {DATA_FOLDER}")
        return

    summary_rows = []
    non_summary_rows = []
    raw_rows = []

    for fname in files:
        full = os.path.join(DATA_FOLDER, fname)
        df = read_csv_safely(full)
        if df.empty:
            continue

        df.columns = [c.strip() for c in df.columns]
        file_date = extract_date_from_filename(fname)
        df["file_name"] = fname
        df["file_date"] = file_date

        if "_summary" in fname.lower():
            summary_rows.append(df)
        else:
            non_summary_rows.append(df)
        raw_rows.append(df)  # all files for raw table

    summary_df = pd.concat(summary_rows, ignore_index=True) if summary_rows else pd.DataFrame()
    non_summary_df = pd.concat(non_summary_rows, ignore_index=True) if non_summary_rows else pd.DataFrame()
    raw_df = pd.concat(raw_rows, ignore_index=True) if raw_rows else pd.DataFrame()

    # Compute time_taken and durationpertrade for non-summary
    if not non_summary_df.empty:
        if "Start Time" in non_summary_df.columns and "End Time" in non_summary_df.columns:
            s = pd.to_datetime(non_summary_df["Start Time"], dayfirst=True, errors="coerce")
            e = pd.to_datetime(non_summary_df["End Time"], dayfirst=True, errors="coerce")
            non_summary_df["time_taken"] = (e - s).dt.total_seconds()
            non_summary_df["duration"] = non_summary_df["time_taken"]

        if "no_of_trades" in non_summary_df.columns:
            trades_num = non_summary_df["no_of_trades"].apply(to_float)
        else:
            trades_num = None

        def compute_dpt(row):
            dur = to_float(row.get("duration"))
            tr = to_float(row.get("no_of_trades")) if trades_num is None else row.get("no_of_trades")
            try:
                if dur is None or tr is None or float(tr) == 0:
                    return None
                return float(dur) / float(tr)
            except:
                return None

        non_summary_df["durationpertrade"] = non_summary_df.apply(compute_dpt, axis=1)

    # ---------------- Prepare Gauges ----------------
    def prepare_gauges(df, prefix):
        gauges = {}
        if df.empty:
            return gauges
        numeric_cols = []
        for col in df.columns:
            if col in ("file_name", "file_date"):
                continue
            if any(keyword in col.lower() for keyword in ["start", "end"]):
                continue
            if any(is_number_like(x) for x in df[col].dropna().astype(str).head(50)):
                numeric_cols.append(col)

        label_cols = [c for c in df.columns if c not in numeric_cols and c not in ("file_name", "file_date")]
        label_keys = [clean_label_key(c) for c in label_cols] + ["file_name", "file_date", "window"]

        for col in numeric_cols:
            metric_name = f"{prefix}_{re.sub(r'[^a-z0-9_]', '_', col.strip().lower())}"
            if "duration" in col.lower() and not metric_name.endswith("_seconds"):
                metric_name += "_seconds"
            try:
                gauge = Gauge(metric_name, f"{metric_name} (from csv column {col})", labelnames=label_keys, registry=CollectorRegistry())
                gauges[col] = (gauge, metric_name, label_keys)
            except ValueError:
                continue
        return gauges

    summary_registry = CollectorRegistry()
    non_summary_registry = CollectorRegistry()
    raw_registry = CollectorRegistry()

    summary_gauges = prepare_gauges(summary_df, "new_data_summary_row")
    non_summary_gauges = prepare_gauges(non_summary_df, "new_data_non_summary_row")

    # Raw table gauge: all columns treated as labels (no numeric metric, just value 1 for Prometheus)
    raw_metric_name = "new_data_raw_table"
    raw_label_keys = [clean_label_key(c) for c in raw_df.columns] + ["window"]
    if not raw_df.empty:
        raw_gauge = Gauge(raw_metric_name, "Raw CSV table", labelnames=raw_label_keys, registry=raw_registry)
        for _, row in raw_df.iterrows():
            windows = windows_for_date(row.get("file_date"), today_date)
            if not windows:
                continue
            for w in windows:
                label_values = [clean_label_value(row.get(c, "unknown")) for c in raw_df.columns] + [w]
                raw_gauge.labels(*label_values).set(1)

    # ---------------- Push Function ----------------
    def push_gauges(df, gauges_map, registry):
        if df.empty or not gauges_map:
            return
        numeric_cols = set(gauges_map.keys())
        for _, row in df.iterrows():
            windows = windows_for_date(row.get("file_date"), today_date)
            if not windows:
                continue
            for w in windows:
                for col, (g, _, label_keys) in gauges_map.items():
                    val = to_float(row.get(col))
                    value_to_set = val if val is not None else 0.0
                    label_values = []
                    for lk in label_keys:
                        label_values.append(clean_label_value(row.get(lk, "unknown")) if lk not in ("file_name","file_date","window") else (
                            clean_label_value(row.get("file_name","unknown")) if lk=="file_name" else (
                                str(row.get("file_date","")) if lk=="file_date" else w
                            )
                        ))
                    try:
                        g.labels(*label_values).set(value_to_set)
                    except Exception as e:
                        print(f"[push_gauges] failed {col}: {e}")

    # ---------------- Push to Gateway ----------------
    if summary_gauges:
        push_gauges(summary_df, summary_gauges, summary_registry)
        try:
            push_to_gateway(PUSHGATEWAY, job=JOB_SUMMARY_RAW, registry=summary_registry)
        except Exception as e:
            print(f"[ERROR] push summary: {e}")

    if non_summary_gauges:
        push_gauges(non_summary_df, non_summary_gauges, non_summary_registry)
        try:
            push_to_gateway(PUSHGATEWAY, job=JOB_NON_SUMMARY_RAW, registry=non_summary_registry)
        except Exception as e:
            print(f"[ERROR] push non-summary: {e}")

    if not raw_df.empty:
        try:
            push_to_gateway(PUSHGATEWAY, job=JOB_RAW_TABLE, registry=raw_registry)
        except Exception as e:
            print(f"[ERROR] push raw table: {e}")

    print("Push completed. Check Pushgateway:", PUSHGATEWAY)

if __name__ == "__main__":
    main()