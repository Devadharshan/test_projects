import os
import psutil
import oracledb
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
from datetime import datetime

# ------------------- CONFIG -------------------
PUSHGATEWAY_URL = "http://localhost:9091"
JOB_NAME = "windows_share_oracle_metrics"

ORACLE_CLIENT_PATH = r"C:\oracle\instantclient_21_12"
ORACLE_DSN = "host:port/service"
ORACLE_USERNAME = "username"
ORACLE_PASSWORD = "password"

ORACLE_QUERY = "SELECT * FROM restoration_logs"

NETWORK_SHARES = [
    r"Z:\\",
    r"Y:\\"
]

LARGE_FILE_THRESHOLD_BYTES = 1 * 1024 * 1024 * 1024  # 1 GB
MAX_DEPTH = 2
MAX_LARGE_FILES_PER_SHARE = 20


# ------------------- FUNCTIONS -------------------
def init_oracle():
    if ORACLE_CLIENT_PATH:
        try:
            oracledb.init_oracle_client(lib_dir=ORACLE_CLIENT_PATH)
        except:
            pass


def query_restoration_logs():
    init_oracle()
    conn = oracledb.connect(
        user=ORACLE_USERNAME,
        password=ORACLE_PASSWORD,
        dsn=ORACLE_DSN
    )
    try:
        cur = conn.cursor()
        cur.execute(ORACLE_QUERY)
        row = cur.fetchone()
        if row:
            colnames = [d[0] for d in cur.description]
            return dict(zip(colnames, row))
        return None
    finally:
        cur.close()
        conn.close()  # ✅ always close


def fast_limited_walk(path, max_depth=2, max_files=20):
    """Fast directory walk with depth & count limit."""
    count = 0
    stack = [(path, 0)]
    while stack:
        current, depth = stack.pop()
        if depth > max_depth:
            continue
        try:
            with os.scandir(current) as it:
                for entry in it:
                    if entry.is_file(follow_symlinks=False):
                        try:
                            size = entry.stat().st_size
                            if size >= LARGE_FILE_THRESHOLD_BYTES:
                                yield entry.path, size
                                count += 1
                                if count >= max_files:
                                    return
                        except:
                            pass
                    elif entry.is_dir(follow_symlinks=False):
                        stack.append((entry.path, depth + 1))
        except:
            pass


# ------------------- PROMETHEUS METRICS -------------------
registry = CollectorRegistry()

g_free_pct = Gauge("network_share_free_percent", "Free share percentage", ["share"], registry=registry)
g_used_pct = Gauge("network_share_used_percent", "Used share percentage", ["share"], registry=registry)
g_large = Gauge("network_share_large_file_gb", "Large files >1GB", ["filepath"], registry=registry)

g_db_numeric = Gauge("restoration_logs_numeric_column", "DB numeric fields", ["column"], registry=registry)
g_db_info = Gauge("restoration_logs_info", "DB snapshot with human readable datetime", ["restore_date"], registry=registry)

g_run_info = Gauge("script_last_run_info", "Timestamp of last run (human readable)", ["time"], registry=registry)


# ------------------- MAIN -------------------
for share in NETWORK_SHARES:
    try:
        usage = psutil.disk_usage(share)
        free_pct = (usage.free / usage.total) * 100
        used_pct = (usage.used / usage.total) * 100

        g_free_pct.labels(share).set(free_pct)
        g_used_pct.labels(share).set(used_pct)

        for filepath, size in fast_limited_walk(share, MAX_DEPTH, MAX_LARGE_FILES_PER_SHARE):
            g_large.labels(filepath).set(size / (1024**3))

    except Exception as e:
        print(f"[WARN] Error scanning share {share}: {e}")


db = query_restoration_logs()
if db:
    restore_date = db.get("RESTORE_DATE")
    if restore_date:
        try:
            restore_str = restore_date.strftime("%Y-%m-%d %H:%M:%S")
        except:
            restore_str = str(restore_date)
        g_db_info.labels(restore_str).set(1)

    for col, val in db.items():
        if isinstance(val, (int, float)):
            g_db_numeric.labels(col).set(val)


run_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
g_run_info.labels(run_time).set(1)

push_to_gateway(PUSHGATEWAY_URL, job=JOB_NAME, registry=registry)

print("✅ Metrics pushed successfully at", run_time)