import re
from datetime import datetime
from collections import defaultdict

from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

# ---------------- CONFIG ----------------
LOG_FILE = r"C:\path\to\your\focus.log"
PUSHGATEWAY = "http://localhost:9091"
JOB_NAME = "focus_log_metrics"

# ---------------- PROM METRICS ----------------
registry = CollectorRegistry()

g_memory = Gauge(
    "focus_message_memory_bytes",
    "Average memory used per message type",
    ["message_type"],
    registry=registry,
)

g_rx_count = Gauge(
    "focus_messages_rx_total",
    "Number of Rx messages",
    ["message_type"],
    registry=registry,
)

g_pr_to_cp = Gauge(
    "focus_pr_to_cp_seconds",
    "Average time from Pr to Cp",
    ["message_type"],
    registry=registry,
)

g_rx_to_cp = Gauge(
    "focus_rx_to_cp_seconds",
    "Average time from Rx to Cp",
    ["message_type"],
    registry=registry,
)

# ---------------- PARSER ----------------

# Example timestamp format: 2024-01-07 00:00:01.234
def parse_time(s):
    return datetime.strptime(s, "%Y-%m-%d %H:%M:%S.%f")

# Storage by correlation id
messages = {}

# Aggregation
stats = defaultdict(lambda: {
    "rx_count": 0,
    "mem": [],
    "pr_cp": [],
    "rx_cp": [],
})

with open(LOG_FILE, "r", encoding="utf-8", errors="ignore") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue

        # ⚠️ You may need to adjust these splits based on exact format
        parts = re.split(r"\s{2,}", line)

        if len(parts) < 8:
            continue

        # Based on your screenshot (approx):
        # 0 = date
        # 1 = time
        # 3 = Rx/Pr/Cp
        # 4 = Message type
        # -2 = correlation id
        # -1 = memory

        date_str = parts[0]
        time_str = parts[1]
        state = parts[3]      # Rx / Pr / Cp
        msg_type = parts[4]   # SERVER.BEAT, CACHE.RELOAD, etc
        corr_id = parts[-2]
        mem_str = parts[-1]

        try:
            ts = parse_time(f"{date_str} {time_str}")
        except:
            continue

        if corr_id not in messages:
            messages[corr_id] = {
                "type": msg_type,
                "rx": None,
                "pr": None,
                "cp": None,
                "mem": None,
            }

        if state == "Rx":
            messages[corr_id]["rx"] = ts
            stats[msg_type]["rx_count"] += 1

        elif state == "Pr":
            messages[corr_id]["pr"] = ts

        elif state == "Cp":
            messages[corr_id]["cp"] = ts
            try:
                messages[corr_id]["mem"] = float(mem_str)
            except:
                pass

# ---------------- CALCULATE ----------------
for corr_id, data in messages.items():
    msg_type = data["type"]
    rx = data["rx"]
    pr = data["pr"]
    cp = data["cp"]
    mem = data["mem"]

    if mem:
        stats[msg_type]["mem"].append(mem)

    if pr and cp:
        stats[msg_type]["pr_cp"].append((cp - pr).total_seconds())

    if rx and cp:
        stats[msg_type]["rx_cp"].append((cp - rx).total_seconds())

# ---------------- EXPORT TO PROM ----------------
for msg_type, s in stats.items():
    if s["mem"]:
        g_memory.labels(msg_type).set(sum(s["mem"]) / len(s["mem"]))

    g_rx_count.labels(msg_type).set(s["rx_count"])

    if s["pr_cp"]:
        g_pr_to_cp.labels(msg_type).set(sum(s["pr_cp"]) / len(s["pr_cp"]))

    if s["rx_cp"]:
        g_rx_to_cp.labels(msg_type).set(sum(s["rx_cp"]) / len(s["rx_cp"]))

# ---------------- PUSH ----------------
push_to_gateway(PUSHGATEWAY, job=JOB_NAME, registry=registry)

print("Metrics pushed successfully.")